<!DOCTYPE HTML>
<!--
	Stellar by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>HumanSys 2025</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="../../assets/css/main.css" />
		<noscript><link rel="stylesheet" href="../../assets/css/noscript.css" /></noscript>
	</head>
	<body class="is-preload">

		<!-- Wrapper -->
			<div>

				<!-- Nav -->
				<nav id="nav">
					<ul>
						<li><a href="#overview" class="active">Overview</a></li>
						<!-- <li><a href="#keynotes">Keynotes</a></li> -->
						<!-- <li><a href="#third">Program</a></li> -->
						<li><a href="#intro" >CFP</a></li>
						<li><a href="#first">Submission</a></li>
						<li><a href="#second">Organization</a></li>
						<li><a href="#fourth">Venue</a></li>
						<li><a href="#fifth">Registration</a></li>
					</ul>
				</nav>

				<!-- Header -->
					<header id="header" class="alt">
						<span><img src="images/humansys_bg_2025.png" alt="" class="header-img2" /></span>
						<div class="header-text">
							<h1>HumanSys 2025</h1>
							<h2>The Third International Workshop on Human-Centered Sensing, Modeling, and Intelligent Systems</h2>
							<h2>Co-located with Cyber-Physical Systems and Internet-of-Things Week 2025</h2>
							<h2>Irvine, USA, May 6-9, 2025</h2>
						</div>
					</header>

				<!-- Main -->
					<div id="main">
						<section id="overview" class="main">

							<div class="content">
								<header class="major">
									<h1><b>Overview</b></h1>
								</header>
								<p>With the rapid progression of urbanization and the increasing emphasis on enhancing human well-being, there is a growing demand for intelligent systems that prioritize human-centric design and functionality. Meeting this demand involves addressing key challenges, such as developing advanced sensing technologies to monitor various aspects of human life, including health indicators, behavioral patterns, and people’s interactions with the built environment. Moreover, it requires developing advanced AI models for human-in-the-loop applications, such as predictive tools for personalized healthcare, adaptive systems for long-term monitoring, and optimization algorithms to enhance daily activities and decision-making processes. Additionally, integrating user requirements into system architectures—encompassing intuitive interfaces, wearable and ambient devices, and context-aware functionalities—remains a critical priority. These advancements are pivotal for a wide range of human-centered applications, including healthcare systems that enable early diagnostics and proactive interventions, smart living environments that streamline and optimize daily routines, personalized learning platforms tailored to individual preferences, and advanced technologies that enhance accessibility and mobility across diverse populations in our community.</p> 
							</div>
						</section>
						<!-- <section id="keynotes" class="main">

							<div class="content">
								<header class="major">
									<h1><b>Keynotes</b></h1>
								</header>


							<h2 id="keynote_1">Wearable AI, WearTel, and Mersivity: Technology as a vessel to interface us to each other and to our surroundings/environment
								</h2>
							<br>
							<div style="display: flex; align-items: center; flex-wrap: wrap;">
								<div style="text-align: center; flex: 0 1 auto; min-width: 100px;">
									<img src="images/Steve_Mann.jpg" width="200px" style="border-radius: 50%;">
									<h2><b><a href="http://wearcam.org/bio.htm" target="_blank" style="text-decoration: none; color: inherit;">Steve Mann</a></b></h2>
								</div>
					
								<div style="margin-left: 2em; flex: 2 1 300px; max-width: 100%">
									<b>Bio: Steve Mann, PhD (MIT '97), P.Eng. (Ontario), Fellow of the IEEE</b>
									<ul>
										<li>Full Professor, University of Toronto</li>
										<li>Visiting Full Professor, Stanford University, Department of Electrical Engineering, Room 216, 350 Serra Mall, Stanford, CA 94305</li>
										<li>Winner of the 2025 IEEE Consumer Electronics Award</li>
										<li>Chair of Silicon Valley Innovation & Entrepreneurship Forum (SVIEF)</li>
										<li>Founding Member of IEEE Council on Extended Intelligence</li>
										<li>Founder of the Water-Human-Computer Interface initiative: the new field of WaterHCI</li>
										<li>Marquis Who's Who 2018 Albert Nelson Marquis Lifetime Achievement Award</li>
										<li>Invented wearable computing in his childhood, brought this invention to MIT to found the MIT wearable computing project, and "persisted in his vision and ended up founding a new discipline." -- Nicholas Negroponte, MIT Media Lab Director, 1997.</li>
										<li>Invented, designed, and built the world's first smartglasses (smart eyeglass) for computer vision.</li>
										<li>Inventor of the world's first contact lens display, and the first implantable eye camera.</li>
										<li>Invented, designed, and built the world's first smartwatch in 1998 (patent filed 1999, featured on cover of Linux Journal July 2000) which he presented at IEEE ISSCC 2000 where he was named "The father of the wearable computer".</li>
										<li>Inventor of HDR (High Dynamic Range) imaging, used in more than 2 billion smartphones.</li>
									</ul>
								</div>

							</div>
							<div style="margin-top: 2em;">
								<h4>Abstract</h4>
								<p>
									Wearable AI is an example of Mersivity. Mersivity regards technology as a vessel that interfaces us to each other and to our surroundings (environment). Indeed, the word "cyborg" (cybernetic organism) originates from the ancient Greek word "kybernetikos", referring to the skill of a helmsman. In the 1960s and 1970s, I created WearTel™️, a wearable telephone which I also envisioned as a wearable camera, wearable computer, etc., combining calculations, computation, and communication. At the time, computers were keeping us imprisoned in offices, whereas I envisioned computation as technology that becomes part of us wherever we want to go. Today we still have computers that imprison us, as we're hunched over, looking at a screen, or immersed in a virtual reality that we can't immerse, i.e., you can't go for a walk or a hike or a swim with it. I believe that if we're going to be surrounded by immersive technology, it should also be exmersive, i.e., immersible/submersible, or at the very least it should connect us with our surroundings -- i.e., it should be "mersive". This requirement gives rise to six fundamental signal flow paths, as outlined in the figure/illustration.
								</p>
								<div style="text-align: center;">
									<div style="text-align: center;">
										<img src="images/SteveMann_Mersivity.png" alt="Mersivity illustration" width="50%">
									</div>
								</div>
							</div>
							
							<style>
								/* Adjust layout for mobile screens */
								@media screen and (max-width: 768px) {
									.bio-container {
										flex-direction: column;
										align-items: center;
										text-align: center;
									}
							
									.bio-text {
										margin-left: 0;
										margin-top: 1em;
									}
								}
							</style>
							
					
								<BR />
					
								<BR />
					
				
							<h2 id="keynote_2">Learning from Shitty Data: Dealing with Behavior Monitoring and Learning in Real-world Deployments</h2>
							<br>
							<div style="display: flex; align-items: center; flex-wrap: wrap;">
								<div style="text-align: center; flex: 0 1 auto; min-width: 100px;">
									<img src="images/zhang-pei705.png" width="200px" style="border-radius: 50%;">
									<h2><b><a href="https://eecs.engin.umich.edu/people/zhang-pei/" target="_blank" style="text-decoration: none; color: inherit;">Pei Zhang</a></b></h2>
								</div>
					
								<div style="margin-left: 2em; flex: 2 1 300px; max-width: 100%">
									<b>Bio: Pei Zhang is an Associate Professor in Department of Electrical Engineering and Computer Science at the University of Michigan, Ann Arbor. He received his bachelor's degree from California Institute of Technology in 2002, and his Ph.D. degree in Electrical Engineering from Princeton University in 2008. His early work ZebraNet is considered one of the seminal works in sensor networks, for which he received the SenSys Test-of-Time Award in 2017. His recent work focuses on Cyber-Physical systems that utilizes the physical properties of vehicles and structures to discover surrounding physical information. His work combines machine learning-based data models, physics-based models, as well as heuristic models to improve learning using small amount of labeled sensor data. His work is applied to field of medicine, farming, smart retail, and is part of multiple startups. His work has been featured in popular media including CNN, CBS, NBC, Science Channel, Discovery Channel, Scientific American, etc. In addition, he has received various best paper awards, the NSF CAREER award (2012), SenSys Test of Time Award (2017), Google faculty award (2013, 2016), and was a member of the Department of Defense Computer Science Studies Panel.</b>
								</div>

							</div>
							<div style="margin-top: 2em;">
								<h4>Abstract</h4>
								<p>
									This talk introduces physics-aided approaches to improve learning in cyber-physical systems (CPS). Learning has become a useful tool for data-rich problems. However, its use in CPS has been limited because of its need for a large amount of well-labeled data for each application and deployment. This is especially challenging and often impossible due to the high number of variables that can affect data distribution in CPS (e.g., weather, time, persons, etc.). This talk introduces combinational techniques that improves physical models and hardware characteristics to enable learning in CPS with “small data”. Specifically we incorporate physical characteristics to guide learning, and transfer data from other domains using the physical understanding. This talk illustrates these approaches through our deployment experiences in real world settings in sports stadiums and farms.
								</p>
							</div>
					

							<br>
								<BR />
					
								<BR />
							</div>
						</section> -->

						<!-- <section id="third" class="main">
							<div class="content">
								<header class="major">
									<h1><b>Program</b></h1>
								</header>
								<h3>Workshop Day: November 4, 2024</h3>
								<ul>
									<li>
										08:00 - 9:00 
											<h3><b>Registration</b></h3>
									</li>
									<li>
										9:00 - 9:10 <h3><b>Welcome</b></h3>
									</li>
									<li>
										9:10 - 10:10
										<h3><b>Keynote Speech</b></h3>
										<ul>
											<li>
												<b>Title:</b> Wearable AI, WearTel, and Mersivity: Technology as a vessel to interface us to each other and to our surroundings/environment
												<br>
												<span class="authors">
													<b>Speaker:</b> Steve Mann
												</span>
											</li>
										</ul>
									</li>
									<li>
										10:10 - 10:30 <h3><b>Break</b></h3>
									</li>
										
									<li>
										10:30 - 11:30
										<h3><b>Session 1: Human-centred Wearable and Sensing Technologies</b></h3>
										<li>
										15 min each, including Q&A
										</li>
										<ul>
											<li>
												Extended Reality Waterball for Spinal Rehabilitation
												<br>
												<span class="authors">
													Steve Mann (MannLab Canada Inc.), Aydin Hosseingholizadeh (MannLab Canada Inc.), Nishant Kumar (MannLab Canada Inc.), Aoran Jiao (MannLab Canada Inc.), Calum Leaver-Preyra (MannLab Canada Inc.)
												</span>
											</li>
											<li>
												Enhancing Parkinson’s Disease Management through Automatic Personalized Assistive Systems
												<br>
												<span class="authors">
													Nasimuddin Ahmed (TCS Research), Aniruddha Sinha (TCS Research), Avik Ghose (TCS Research)
												</span>
											</li>
											<li>
												Taming the Variability of Soft Sensors
												<br>
												<span class="authors">
													Chien-Ti Hsiao (National Taiwan University), Tzu-Chin Ho (National Taiwan University), Hsuan-Ying Liu (National Taiwan University), Yan-Chi Lu (National Taiwan University), Kate Ching-Ju Lin (National Yang Ming Chiao Tung University), Ling-Jyh Chen (Academia Sinica, Taiwan), Polly Huang (National Taiwan University)
												</span>
											</li>
											<li>
												Integrating Traditional Japanese Nishijin Weaving Techniques with Modern Electronics
												<br>
												<span class="authors">
													Norihisa Segawa (Kyoto Sangyo University), Shuo Zhou (Kyoto Sangyo University), Masato Yazawa (Mathematical Assist Design Laboratory), Kaori Ueda (Kyoto Saga University of Arts)
												</span>
											</li>
										</ul>
									</li>
									<li >
										12:00 - 13:30
										<h3><b>Lunch</b></h3>
										
									</li>
									<li >
										13:30 - 14:30
											<h3><b>Keynote Speech</b></h3>
											<ul>
												<li>
													Title: Learning from Shitty Data: Dealing with Behavior Monitoring and Learning in Real-world Deployments
													<br>
													<span class="authors">
														<b>Speaker:</b>Pei Zhang
													</span>
												</li>
											</ul>
									</li>
									<li>
										14:30 - 15:15
										<h3><b>Session 2: Sensor Fusion and Embedded Systems</b></h3>
										<li>
											15 min each, including Q&A
										</li>
										<ul>
											<li>
												Underwater Ranging with a Single Smartphone
												<br>
												<span class="authors">
													Liu Yang (Zhejiang University), Zhi Wang (Zhejiang University)
												</span>
											</li>
											<li>
												Hierarchical Demand Based Resource Allocation for On-Device Inference
												<br>
												<span class="authors">
													Ashok Samraj Thangarajan (Nokia Bell Labs), Fahim Kawsar (Nokia Bell Labs), Alessandro Montanari (Nokia Bell Labs)
												</span>
											</li>
											<li>
												Energy Characterization of Tiny AI Accelerator-Equipped Microcontrollers
												<br>
												<span class="authors">
													Yushan Huang (Imperial College London), Taesik Gong (UNIST), SiYoung Jang (Nokia Bell Labs), Fahim Kawsar (Nokia Bell Labs & University of Glasgow), Chulhong Min (Nokia Bell Labs)
												</span>
											</li>
										</ul>
									</li>
									<li >
										15:15 - 15:30
											<h3><b>Closing Remarks and Best Paper Award announcement</b></h3>
									</li>
								</ul>
							</div>
						</section> -->
						<!-- Introduction -->
						<section id="intro" class="main">

							<div class="content">
								<header class="major">
									<h1><b>Call for Papers</b></h1>
								</header>
								<!-- <p>We will solicit papers in three categories:</p>

								<h3>1. Full Papers</h3>
								<p><strong>Length:</strong> Up to 6 pages (including references)</p>
								<p>Full papers should report reasonably mature work in human-centered sensing, modeling, or intelligent systems. These papers are expected to demonstrate concrete and reproducible results, even if the scale may be limited.</p>
							
								<h3>2. Experience Papers</h3>
								<p><strong>Length:</strong> Up to 4 pages (including references)</p>
								<p>Experience papers should present experiences with the implementation, deployment, and operation of novel sensing or modeling technologies and systems for human-centered applications. Desirable papers are expected to include real data and descriptions of practical lessons learned.</p>
							
								<h3>3. Short Papers</h3>
								<p><strong>Length:</strong> Up to 2 pages (including references)</p>
								<p>Short papers are encouraged to report novel and creative ideas that have yet to produce concrete research results but are at a stage where community feedback would be useful.</p> -->
								<p>This workshop aims to foster collaboration among researchers and practitioners from academia, industry, and service sectors, providing a platform to share ideas and experiences in developing human-centered systems. </p>
								
								<h2>Topics of Interest</h2>
								<p>We welcome contributions that emphasize human-centric sensing technologies, novel models for human-centered systems, and applications in areas including, but not limited to:</p>
								
								<h3>Human-Centered Sensing and Data Acquisition</h3>
								<ul>
									<li>Novel sensing approaches for health, activity, gesture, behavior monitoring of individuals or groups (e.g., camera, VR/AR, wearables, mobile platforms, vibration, acoustics, IMU, mmWave/WiFi, etc.)</li>
									<li>Data management transmission methodologies (e.g., communication and networking)</li>
								</ul>

								<h3>Human-Centered Static and AI Driven Models</h3>
								<ul>
									<li>Statistical models for representing and analyzing human behavior, preferences, and environmental interactions include methods (e.g., regression analysis, Bayesian networks, clustering algorithms, matrix factorization techniques, etc.) that capture relationships within human-centered data.</li>
									<li>Advanced AI models and techniques involving data collected from humans (e.g., large language models, convolutional neural networks, transformers, graph neural networks, time series models, statistical learning models, etc.).</li>
									<li>System models or frameworks for human-in-the-loop applications.</li>
									<li>Data interpretation and metric prediction in human-centered cyber-physical systems.</li>
								</ul>

								<h3>Human-Centered System Design and Implementation</h3>
								<ul>
									<li>Integration of human needs and preferences in the design of cyber-physical systems (e.g., privacy considerations, UI/UX design, integration of LLM agents, etc.)</li>
									<li>Prototyping and iterative system design to refine and validate human-centered solutions.</li>
								</ul>

								<h3>Applications and Real-World Studies</h3>
								<ul>
									<li>Real-world deployment experience with human participants</li>
									<li>Evaluation methodologies and insights of cyber-physical systems with human in the loop</li>
								</ul>
							</div>
								

						</section>

					<!-- First Section -->
						<section id="first" class="main">
							<div class="content">
								<header class="major">
									<h1><b>Submission</b></h1>
								</header>
								<p>Submitted papers must be unpublished and must not be currently under review for any other publication. 
									<p>We will solicit papers in <u>three</u> categories:</p>
									<ol>
										<li><u>Full Papers</u> (up to 6 pages including references) should report reasonably mature work in human-centered sensing, networking, or multi-device systems. These papers are expected to demonstrate concrete and reproducible results, even if the scale may be limited.</li>
										<li><u>Experience Papers</u> (up to 4 pages including references) should present experiences with the implementation, deployment, and operation of novel sensing or networking technologies and systems for human-centered applications. Desirable papers are expected to include real data and descriptions of practical lessons learned.</li>
										<li><u>Short Papers</u> (up to 2 pages including references) are encouraged to report novel and creative ideas that have yet to produce concrete research results but are at a stage where community feedback would be useful.</li>
										<!-- <li><u>Short Papers</u>(up to 2 pages including references) of papers that have been presented at SenSys are welcome to obtain feedback from the dedicated human sensing community. These should be entitled “Excerpt of SENSYS PAPER TITLE"</li> -->
									</ol>
									<p>All papers will be at most <strong> 6 single-spaced 8.5” x 11” pages</strong> with <strong>10-pt font size in two-column format, including figures, tables</strong>, and references. All submissions must use the LaTeX (preferred) or Word styles found <a href="http://www.acm.org/publications/proceedings-template" target="_blank">here</a>. LaTeX submissions should use the <code>acmart.cls</code> template (<code>sigconf</code> option), with the 10-pt font. All of the accepted papers (regardless of category) will be included in the ACM Digital Library.  All papers will be digitally available through the workshop website, and the ACM Sensys 2024 Adjunct Proceedings. We will offer a "<u>Best Paper</u>" award, sponsored by Nokia Bell Labs, to one of the accepted papers.</p> 
									<!-- Please refer to publication chair's <a href="http://sensys.acm.org/2017/resources/documents/HowTo.pdf">Note</a> as well as the User Guide of the new class.  -->
							
									<!-- <span style="color:red;"> ToDo </span> -->

								<p>By submitting your article to an ACM Publication, you are hereby acknowledging that you and your co-authors are subject to all ACM Publications Policies, including ACM's new Publications Policy on Research Involving Human Participants and Subjects. Alleged violations of this policy or any ACM Publications Policy will be investigated by ACM and may result in a full retraction of your paper, in addition to other potential penalties, as per ACM Publications Policy. https://www.acm.org/publications/policies/research-involving-human-participants-and-subjects</p>

								<p>Please ensure that you and your co-authors obtain an ORCID ID, so you can complete the publishing process for your accepted paper. ACM has been involved in ORCID from the start and we have recently made a commitment to collect ORCID IDs from all of our published authors. We are committed to improve author discoverability, ensure proper attribution and contribute to ongoing community efforts around name normalization; your ORCID ID will help in these efforts.</p>

								<p>HumanSys’25 follows a single-blind review process.</p>

								<p>Please submit your papers via this link -  <a href="https://humansys25.hotcrp.com/">https://humansys25.hotcrp.com/</a>  
								</p>

								<h3>Important dates</h3>
								<ul>
									<!-- <span style="color:red;"> TBC</span> -->
									<ul>
										<li><strong>Paper Registration Deadline:</strong> <s>3 Mar, 2025</s> → 10 Mar, 2025, 23:59 AOE</li>
										<li><strong>Submission Deadline:</strong> 10 Mar, 2025, 23:59 AOE</li>
										<li><strong>Notification of Acceptance:</strong> 24 Mar, 2025</li>
										<li><strong>Camera Ready:</strong> 31 Mar, 2025</li>
										<li><strong>Workshop Date:</strong> 6 May, 2025</li>
									</ul>
									
								</ul>
							</div>
						</section>							
						<!-- Second Section -->
							<section id="second" class="main">
								<div class="content">
									<header class="major">
										<h1><b>Organization</b></h1>
									</header>

									<h4>General Chairs</h4>
									<ul>
										<li>Yiwen Dong (yiwen@illinois.edu, University of Illinois Urbana-Champaign, USA) </li>
										<li>Sijie Ji (sijieji@caltech.edu, California Institute of Technology, USA)</li>
										<li>Yang Liu (yang.16.liu@nokia-bell-labs.com, Nokia Bell Labs, UK) </li>
									</ul>
									<h4>Program Chairs</h4>
									<ul>
										<li>Jingping Nie (jn2551@columbia.edu, Columbia University, USA) </li>
										<li>Huining Li (hli83@ncsu.edu, North Carolina State University, USA)</li>
									</ul>
									<h4>Publicity Chair</h4>
									<ul>
										<li>Stephen Xia (stephen.xia@northwestern.edu, Northwestern University, USA)</li>
									</ul>
									<h4>Social Media Chairs</h4>
									<ul>
										<li>Ziyi Xuan (zix222@lehigh.edu,Lehigh University, USA)</li>
										<li>Yuang Fan (yf2676@columbia.edu, Columbia University,USA)</li>
									</ul>
									<h4>Web Chair</h4>
									<ul>
										<li>Harshvardhan Takawale (htakawal@umd.edu, University of Maryland College Park, USA) </li>
									</ul>

									<h4>Steering Committee Members</h4>
									<ul>
										<li>Alessandro Montanari (Nokia Bell Labs, UK)</li>
										<li>Fred Xiaofan Jiang (Columbia University, USA)</li>
										<li>Mani Srivastava (University of California, Los Angeles)</li>
										<li>Pei Zhang (University of Michigan, USA)</li>
									</ul>
									<h4>Technical Program Committee</h4>
									<ul>
									<li>Dong Li (dli@umbc.edu, University of Maryland, Baltimore County, USA)</li>
									<li>Yu Yang (yuyang@lehigh.edu, Lehigh University, USA)</li>
									<li>Ashok Samraj Thangarajan (ashok.thangarajan@nokia-bell-labs.com, Nokia Bell Labs, UK)</li>
									<li>Ying Chen (ychen62@kennesaw.edu, Kennesaw State University, USA)</li>
									<li>Yang Liu (yl868@cam.ac.uk, University of Cambridge, UK)</li>
									<li>Hanqing Guo (guohanqing@hawaii.edu, University of Hawaiʻi at Mānoa, USA)</li>
									<li>Zhenyu Yan (zyyan@ie.cuhk.edu.hk, Chinese University of Hong Kong, China)</li>
									<li>VP Nguyen (vp.nguyen@cs.umass.edu, University of Massachusetts Amherst, USA)</li>
									<li>Qiang Yang(qy258@cam.ac.uk, University of Cambridge, UK)</li>
									<li>Marios Constantinides (marios.constantinides@cyens.org.cy, CYENS Centre of Excellence,
									Cyprus)</li>
									<li>Zongxing Xie (zxie1@kennesaw.edu, Kennesaw State University)</li>
									<li>Andrea Ferlini (andrea.ferlini@nokia-bell-labs.com, Nokia Bell Labs, UK)</li>
									<li>Ting Dang (ting.dang@unimelb.edu.au, The University of Melbourne, Australia)</li>
									<li>Khaldoon Al-Naimi (khaldoon.al-naimi@nokia-bell-labs.com, Nokia Bell Labs, UK)</li>
									<li>Dong Ma (dongma@smu.edu.sg, Singapore Management University, Singapore)</li>
									<li>Ananta Narayanan Balaji (ananta.balaji@nokia.com, Nokia Bell Labs, UK)</li>
									<li>Longfei Shangguan(longfei@pitt.edu, University of Pittsburgh, USA)</li>
									<li>SiYoung Jang (siyoung.jang@nokia-bell-labs.com, Nokia Bell Labs, UK)</li>
									<li>Tao Chen (tac194@pitt.edu, University of Pittsburgh, USA)</li>
									<li>Soumyajit Chatterjee (soumyajit.chatterjee@nokia-bell-labs.com, Nokia Bell Labs, UK)</li>
									<li>Shirui Cao (shiruicao@cs.umass.edu, University of Massachusetts Amherst, USA)</li>
									</ul>
								</div>
							</section>



							<section id="fourth" class="main">
								<div class="content">
									<header class="major">
										<h1><b>Venue</b></h1>
									</header>
									<p>
										<!-- <span style="color:red;"> TBC</span> -->
										<!-- HumanSys 2024 will be held as a joint workshop in conjunction with ACM SenSys and ACM BuildSys 2024 in Hangzhou, China.<br><br>For further information on accommodation, VISA, and travel arrangements, please find more details on the SenSys website at <a href="https://sensys.acm.org/2024/">https://sensys.acm.org/2024/</a> and BuildSys website at <a href="https://buildsys.acm.org/2024/">https://buildsys.acm.org/2024/</a> -->
										HumanSys 2025 will be held as a joint workshop in conjunction with CPS-IoT Week 2025 in Irvine, California, from May 6 to 9, 2025. <br><br>
										For further information on accommodation, VISA, and travel arrangements, please find more details on the CPS-IoT Week website at <a href="https://cps-iot-week2025.ics.uci.edu/venue.php#main">https://cps-iot-week2025.ics.uci.edu/venue.php#main</a>
									</p> 
								</div>
							</section>

							<section id="fifth" class="main">
								<div class="content">
									<header class="major">
										<h1><b>Registration</b></h1>
									</header>
									<p>
										<!-- <span style="color:red;"> TBC</span> -->
										HumanSys 2025 will be held as a joint workshop in conjunction with CPS-IoT Week 2025 in Irvine, California.<br><br>Please visit <a href="https://cps-iot-week2025.ics.uci.edu/calls.php#main">https://cps-iot-week2025.ics.uci.edu/calls.php#main</a> for more information.
									</p>
								</div>
							</section>



					</div>

				<!-- Footer -->
					<footer id="footer">
						<section> 
							<ul class="icons">
								<li><a href="https://x.com/Humansys24/status/1818648063788937279" class="icon brands fa-twitter alt"><span class="label">Twitter</span></a></li>
								<li><a href="https://www.linkedin.com/company/acm-humansys/" class="icon brands fa-linkedin alt"><span class="label">LinkedIn</span></a></li>
								<li><a href="https://www.facebook.com/share/p/qRKHy1K7cWMLXe6v/?mibextid=xfxF2i" class="icon brands fa-facebook-f alt"><span class="label">Facebook</span></a></li>
								<!-- <li><a href="#" class="icon brands fa-instagram alt"><span class="label">Instagram</span></a></li> -->
							</ul>
						</section>
						<p class="copyright">&copy;  HumanSys 2025: The Third International Workshop on Human-Centered Sensing, Modeling, and Intelligent Systems.</p>
					</footer>

			</div>

		<!-- Scripts -->
			<script src="../../assets/js/jquery.min.js"></script>
			<script src="../../assets/js/jquery.scrollex.min.js"></script>
			<script src="../../assets/js/jquery.scrolly.min.js"></script>
			<script src="../../assets/js/browser.min.js"></script>
			<script src="../../assets/js/breakpoints.min.js"></script>
			<script src="../../assets/js/util.js"></script>
			<script src="../../assets/js/main.js"></script>

	</body>
</html>
